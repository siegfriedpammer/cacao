\section{Related Work}
\label{sec:related}

Section \ref{sec:constantprop} introduced a simple algorithm which combines both constant folding and constant propagation. It discovers values which are statically known to be constant and uses this information to evaluate expressions at compile-time. Nevertheless, this optimization is based on assumptions which restrict the number of detected constant expressions. Basically, it supposes that all instructions in the program can be reached, but for an improvement of the optimization results, this assumption has to be dropped. What has to be considered is the evaluation of constant conditions. Obviously, if a result of a condition test can be computed at compile-time, it will be possible to gain information about which branches will never be executed during run-time. These unreachable code sections can then be ignored by further optimization and will be deleted from the program which is also referred to as \emph{unreachable code elimination} \cite{appel:2004:moderncompilerimpl}. Furthermore, the removal of conditional branches can have another positive effect, namely for the propagation of constants: The search for constants can now be restricted to the reachable branches which possibly yields propagation possibilities that have not been discovered before. Obviously, further propagation can raise additional potential regarding evaluation of condition tests which again could lead to the deletion of branches.

An approach  that combines both constant propagation and unreachable code elimination is followed by a technique called \emph{conditional constant propagation} \cite{wegman:1991:constantpropagation}. In contrast to the algorithm presented in section \ref{sec:constantprop}, it propagates values only to those code parts which are already known to be reachable. That means, based on symbolic execution, this optimization starts at the beginning of the program and continues by exploring which further code sections can be reached, where constant propagation will proceed. Wegman and Zadeck \cite{wegman:1991:constantpropagation} also give a formulation of this optimization which takes advantage of static single assignment form, called \emph{sparse conditional constant propagation}.

Another field, that offers various techniques yielding similar optimization results, regards the removal of redundancies in programs. This involves the discovery of equivalent expressions which, as mentioned earlier in section \ref{sec:global-value-numbering}, is known to be an undecidable problem. Besides the presented formulation of global value numbering, which discovers certain equivalencies based on the congruence of expressions, there exist a number of alternative techniques that strive to find preferably large portions of redundant computations. One of those techniques is referred to as \emph{partial redundancy elimination} which, in contrast to global value numbering, follows a lexical approach. This means, it identifies expressions that are textually congruent and allows for discovery of redundant computations which are not necessarily value-congruent \cite{click:1995:combininganalyses}.
The scope of this optimization spans the detection and removal of redundancies which occur along some but not necessarily along all paths through a program. These are also referred to as \emph{partial redundancies} \cite{aho:2006:compilersprinciples}.
More generally, it also detects \emph{common sub-expressions} and \emph{loop-invariant code} which can be viewed as special types of partial redundancies. Once this optimization has discovered redundant computations, it will delete or relocate the according expressions, so that they will be evaluated only as often as necessary during execution of the program.

In general, the portions of redundancies found by global value numbering and partial redundancy elimination are overlapping, however, the two optimizations do not find exactly the same equivalencies. According to Click \cite{click:1995:gcm-gvn}, in practice, global value numbering can be expected to find more redundancies than partial redundancy elimination. Approaches exist that try to combine both techniques to maximize the number of detected redundant expressions \cite{vandrunen:2004:pre-gvn}.